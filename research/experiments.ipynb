{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hamza\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Hamza\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import pinecone\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from pdf\n",
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(\n",
    "        data, \n",
    "        glob = \"*.pdf\",\n",
    "        loader_cls = PyPDFLoader\n",
    "    )\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 500, \n",
    "        chunk_overlap = 20\n",
    "    )\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    \n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of my chunk: 7020\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"Length of my chunk:\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download embedding model\n",
    "def download_hugging_face_embedding_model():\n",
    "    embeddings = HuggingFaceBgeEmbeddings(\n",
    "        model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    )\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceBgeEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, query_instruction='Represent this question for searching relevant passages: ', embed_instruction='', show_progress=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embedding_model()\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello World\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.010300836525857449, 0.1830792874097824, 0.030811207368969917, 0.004452838096767664, -0.027336152270436287, -0.03356252610683441, 0.037631504237651825, -0.03157331794500351, -0.003390994854271412, -0.008950844407081604, 0.03803613409399986, -0.051291029900312424, 0.00036832180921919644, -0.02372707426548004, 0.0927102267742157, -0.027795836329460144, -0.03515258803963661, -0.003224171930924058, -0.07681781053543091, -0.05761216953396797, 0.07257597893476486, 0.11128545552492142, 0.016058532521128654, 0.01590849459171295, -0.08232702314853668, 0.0070072864182293415, 0.02901313453912735, 0.0011386657133698463, 0.11671734601259232, -0.03232727572321892, -0.032271608710289, -0.0012589985271915793, 0.10591629147529602, 0.023600837215781212, 0.009664943441748619, 0.09834079444408417, 0.04293632134795189, -0.01954762451350689, 0.019267864525318146, -0.06417106837034225, 0.0239233560860157, -0.05288010463118553, -0.02646954171359539, 0.005548680666834116, -0.017025195062160492, -0.030232716351747513, -0.09035339951515198, 0.054188285022974014, 0.032783232629299164, -0.03849177807569504, -0.1629096418619156, -0.05710047483444214, -0.06604950875043869, -0.014481844380497932, 0.04974616691470146, -0.010199381969869137, -0.06685131788253784, -0.0010846988297998905, 0.028305649757385254, -0.021520165726542473, -0.03531769663095474, 0.025931140407919884, -0.01971502974629402, 0.06278973817825317, 0.0917641669511795, -0.10229229927062988, 0.03703523799777031, 0.02054440602660179, -0.07321774959564209, -0.038438715040683746, -0.10208164900541306, -0.021372688934206963, -0.04500989615917206, -0.01880411058664322, -0.13577798008918762, -0.03678479045629501, -0.034859947860240936, -0.03833592310547829, -0.01651899516582489, -0.031229380518198013, 0.06781851500272751, 0.020737268030643463, 0.011971947737038136, 0.0718044713139534, -0.004278066102415323, 0.024945497512817383, 0.016519002616405487, -0.06834040582180023, 0.04903169348835945, -0.006629368290305138, -0.07006296515464783, -0.09807820618152618, 0.03884945064783096, 0.011759728193283081, -0.010465756058692932, 0.05174495279788971, 0.04994416981935501, 0.021490396931767464, 0.02207813784480095, 0.11860287189483643, 0.08999454230070114, 0.03394397348165512, 0.08883439004421234, 0.02232237718999386, -0.022453971207141876, 0.011377060785889626, -0.101294606924057, 0.06914237141609192, 0.014844400808215141, -0.04821134731173515, -0.09350987523794174, -0.05377846211194992, -0.03811458498239517, -0.10190242528915405, 0.040902286767959595, -0.06833648681640625, 0.022506853565573692, 0.015452048741281033, -0.02008037641644478, 0.03599824011325836, -0.02419486828148365, -0.008909265510737896, -0.007182086352258921, 0.036518365144729614, -0.03508390113711357, -0.017105242237448692, -0.020168781280517578, -2.2842639688720557e-33, 0.09506480395793915, 0.006659995298832655, 0.021885273978114128, 0.09388472139835358, -0.03544972464442253, -0.003322196425870061, -0.04450341686606407, 0.042568303644657135, 0.029856620356440544, -0.013110718689858913, 0.007181514985859394, 0.02030736207962036, 0.0015097850700840354, 0.02846391499042511, -0.05009438842535019, -0.03787592798471451, -0.06964103877544403, 0.019164979457855225, -0.069520503282547, 0.07272635400295258, -0.014777932316064835, -0.015872696414589882, 0.0013892221031710505, 0.02643931470811367, 0.060565367341041565, 0.005688164383172989, 0.01108040101826191, -0.08853626251220703, 0.025121871381998062, 0.021633928641676903, 0.03881045803427696, -0.045131292194128036, -0.04619201272726059, -0.04280679300427437, 0.06965947151184082, 0.09090015292167664, -0.01369092334061861, -0.08157452940940857, -0.06711918860673904, -0.055572330951690674, -0.046760380268096924, 0.03963346779346466, 0.07059670984745026, 0.005815847776830196, 0.030685991048812866, 0.0279759019613266, -0.05543592572212219, 0.005270824301987886, -0.0005426334100775421, 0.08524663001298904, -0.020388595759868622, 0.07555059343576431, -0.09101557731628418, -0.028498012572526932, 0.05228206887841225, 0.04848283529281616, -0.028915297240018845, 0.0685204416513443, -0.043926920741796494, 0.07083983719348907, -0.00945504941046238, 0.008037055842578411, 0.04271795600652695, 0.05201654136180878, -0.03763117641210556, -0.019753556698560715, -0.026938602328300476, -0.02277463674545288, 0.045056264847517014, 0.0026521726977080107, -0.03637433797121048, -0.0016245674341917038, -0.009545058012008667, 0.08428996801376343, -0.0331655852496624, -0.004807301331311464, 0.005520852282643318, -0.04377118870615959, -0.007754727732390165, -0.06770294904708862, -0.006247985176742077, 0.008232713676989079, 0.029952479526400566, 0.05353197082877159, 0.07379396259784698, -0.07401298731565475, 0.04543823376297951, -0.1214526891708374, 0.0067869070917367935, 0.02322908118367195, -0.025053538382053375, 0.0705210417509079, -0.0025635152123868465, -0.10330290347337723, -0.06143463775515556, -4.5544212938091486e-35, 0.09373198449611664, 0.016521796584129333, -0.051285456866025925, -0.007563093677163124, -0.05882896110415459, -0.01072101853787899, -0.03885474428534508, 0.06002240255475044, 0.005357753485441208, 0.08408884704113007, -0.011622545309364796, 0.010504464618861675, 0.13890968263149261, -0.013992756605148315, -0.07269318401813507, -0.04701690375804901, 0.10752875357866287, -0.0030042605940252542, 0.010074431076645851, 0.06560283899307251, 0.003994026221334934, 0.01095564290881157, -0.09632877260446548, -0.02518204227089882, 0.015337633900344372, 0.07056564092636108, 0.08489099144935608, -0.025677930563688278, -0.07766716927289963, 0.008598227985203266, 0.009575273841619492, 0.007218647748231888, -0.09409841895103455, 0.0414709746837616, -0.045654937624931335, -0.007441794965416193, 0.014582674019038677, 0.006933525204658508, 0.0029329012613743544, -0.05206768587231636, 0.002741094445809722, 0.021477889269590378, 0.011189437471330166, 0.06323128193616867, -0.08215916156768799, -0.005953996907919645, -0.026612399145960808, 0.06312450766563416, -0.009564969688653946, -0.02802591770887375, -0.03727740794420242, -0.03191065043210983, 0.043135713785886765, -0.08780162036418915, -0.059518661350011826, -0.0228080116212368, -0.06337305158376694, -0.043727975338697433, 0.026400696486234665, -0.031030455604195595, 0.004854721017181873, 0.03686678782105446, 0.0022787759080529213, 0.05558502674102783, 0.02213158831000328, -0.07549657672643661, 0.009231259115040302, 0.07583916187286377, 0.021181771531701088, -0.08696749806404114, -0.009340724907815456, -0.07346439361572266, -0.040603771805763245, -0.016280842944979668, -0.014284401200711727, 0.053436268121004105, 0.036426763981580734, -0.06934581696987152, -0.0260628592222929, 0.04452916234731674, 0.03905075043439865, 0.0022511612623929977, -0.05344933271408081, 0.019616790115833282, 0.03297466039657593, -0.017909809947013855, -0.004217448644340038, 0.054069895297288895, 0.025197923183441162, 0.023361612111330032, -0.04513728991150856, 0.01531977392733097, -0.06090223044157028, -0.01031135767698288, 0.0050229597836732864, -2.2991844872422007e-08, -0.07419107854366302, 0.02353012189269066, -0.03804842382669449, 0.03680158033967018, 0.036406587809324265, 0.03847787529230118, 0.05947578698396683, -0.039882510900497437, -0.0797484740614891, 0.0250023752450943, 0.03533360734581947, 0.08019211888313293, -0.05820675939321518, -0.024035582318902016, 0.0684947595000267, 0.06681925058364868, -0.00875752791762352, -0.06276894360780716, -0.06686686724424362, 0.0013597141951322556, 0.07438522577285767, 0.0626690536737442, -0.022049112245440483, 0.01517870370298624, -0.04246605187654495, 0.04371561110019684, -0.002968402113765478, 0.032307837158441544, -0.07244179397821426, -0.008453109301626682, 0.02477753534913063, 0.10374247282743454, -0.08862137794494629, 0.00780539819970727, -0.04052716866135597, 0.0046877022832632065, -0.08092759549617767, 0.001834092428907752, 0.0505838543176651, -0.05548543483018875, 0.006174094974994659, 0.08420971035957336, 0.011475914157927036, -0.0007286117179319263, 0.03322440758347511, 0.015147855505347252, 0.015199841931462288, 0.009150318801403046, -0.043916475027799606, -0.0545680969953537, -0.08241593092679977, -0.0029428666457533836, 0.059404678642749786, -0.0029332025442272425, 0.022356022149324417, 0.05346649885177612, 0.024953091517090797, 0.05151025205850601, -0.019081268459558487, 0.02093016542494297, 0.1539037525653839, 0.039949916303157806, 0.027571871876716614, -0.027968114241957664]\n"
     ]
    }
   ],
   "source": [
    "print(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Pinecone client\n",
    "pinecone = Pinecone(\n",
    "    api_key = PINECONE_API_KEY,\n",
    "    serverless = ServerlessSpec(\n",
    "        cloud = 'aws',\n",
    "        region = 'us-east-1'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Specify your index\n",
    "index_name = \"medical-chatbot\"\n",
    "\n",
    "# Creating Embeddings for Each of The Text Chunks & storing\n",
    "doc_search = PineconeVectorStore.from_texts(\n",
    "    [t.page_content for t in text_chunks], \n",
    "    embeddings, \n",
    "    index_name = index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result [Document(id='6e9f7130-17a6-4e8b-ac66-8dfcc7b05aa7', metadata={}, page_content='allergens are the following:\\n• plant pollens\\n• animal fur and dander\\n• body parts from house mites (microscopic creatures\\nfound in all houses)\\n• house dust• mold spores• cigarette smoke• solvents• cleaners\\nCommon food allergens include the following:\\n• nuts, especially peanuts, walnuts, and brazil nuts\\n• fish, mollusks, and shellfish• eggs• wheat• milk• food additives and preservatives\\nThe following types of drugs commonly cause aller-\\ngic reactions:\\n• penicillin or other antibiotics'), Document(id='e675f47e-a9f8-49a2-9491-03447194cf35', metadata={}, page_content='When thisoccurs, an allergy develops against the offending sub-stance (an allergen.)'), Document(id='df9bfb6a-c6a0-4d6b-b5cb-8c6557d39ef8', metadata={}, page_content=\"GALE ENCYCLOPEDIA OF MEDICINE 2 117Allergies\\nAllergic rhinitis is commonly triggered by\\nexposure to household dust, animal fur,or pollen. The foreign substance thattriggers an allergic reaction is calledan allergen.\\nThe presence of an allergen causes the\\nbody's lymphocytes to begin producingIgE antibodies. The lymphocytes of an allergy sufferer produce an unusuallylarge amount of IgE.\\nIgE molecules attach to mast\\ncells, which contain histamine.HistaminePollen grains\\nLymphocyte\\nFIRST EXPOSURE\")]\n"
     ]
    }
   ],
   "source": [
    "#If we already have an index we can load it like this\n",
    "doc_search = PineconeVectorStore.from_existing_index(index_name, embeddings)\n",
    "\n",
    "query = \"What are Allergies\"\n",
    "\n",
    "docs = doc_search.similarity_search(query, k=3)\n",
    "\n",
    "print(\"Result\", docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = PromptTemplate(\n",
    "    template = prompt_template, \n",
    "    input_variables = [\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = CTransformers(\n",
    "        model = \"model/llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "        model_type = \"llama\",\n",
    "        config = {\n",
    "                 'max_new_tokens' : 512,\n",
    "                 'temperature' : 0.8\n",
    "                }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm = llm, \n",
    "    chain_type = \"stuff\", \n",
    "    retriever = doc_search.as_retriever(\n",
    "        search_kwargs = {'k': 2}\n",
    "    ),\n",
    "    return_source_documents = True, \n",
    "    chain_type_kwargs = chain_type_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input = input(f\"Input Prompt:\")\n",
    "    result = qa.invoke({\"query\": user_input})\n",
    "    print(\"Response : \", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
